import os
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.llms import LlamaCpp

# === 1. åŠ è½½å¹¶åˆ†å—çŸ¥è¯†åº“ ===
with open("knowledge.txt", "r", encoding="utf-8") as f:
    text = f.read()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
chunks = text_splitter.create_documents([text])

# === 2. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ + æ„å»ºå‘é‡åº“ ===
embeddings = HuggingFaceBgeEmbeddings(
    model_name="BAAI/bge-small-en-v1.5",
    model_kwargs={"device": "cpu"},
    encode_kwargs={"normalize_embeddings": True}
)
vector_store = FAISS.from_documents(chunks, embeddings)

# === 3. åˆå§‹åŒ–æœ¬åœ° LLM ===
llm = LlamaCpp(
    model_path="./models/mistral-7b-instruct-v0.2.Q4_K_M.gguf",
    n_ctx=2048,
    n_threads=8,
    n_gpu_layers = 40,
    verbose=False
)

# === 4. æ‰‹åŠ¨æ‹†åˆ† RAG æ­¥éª¤ ===
def rag_step_by_step(query: str, k: int = 2):
    # ğŸ” æ­¥éª¤ 1: æ£€ç´¢çŸ¥è¯†åº“ â†’ è·å– context
    retriever = vector_store.as_retriever(search_kwargs={"k": k})
    docs = retriever.invoke(query)
    
    # æå–æ–‡æœ¬å†…å®¹ï¼ˆå¯é€‰ï¼šä¿ç•™å…ƒæ•°æ®ï¼‰
    context = "\n\n".join([doc.page_content for doc in docs])
    print(f"ğŸ” æ£€ç´¢åˆ° {len(docs)} æ®µç›¸å…³æ–‡æ¡£:\n{context}\n{'-'*50}")
    
    # ğŸ§  æ­¥éª¤ 2: æ‰‹åŠ¨æ„é€  prompt
    prompt = f"""[INST]
Use only the following context to answer the question.
If you don't know, say "I don't know based on the provided information."

Context:
{context}

Question: {query}
[/INST]
Answer:
"""
    
    # ğŸ¤– æ­¥éª¤ 3: è°ƒç”¨å¤§æ¨¡å‹
    response = llm.invoke(prompt)
    #response = prompt
    return response.strip(), docs

# === 5. äº¤äº’å¼é—®ç­” ===
if __name__ == "__main__":
    print("âœ… æ‹†åˆ†ç‰ˆ RAG å·²å¯åŠ¨ï¼è¾“å…¥é—®é¢˜ï¼ˆ'exit' é€€å‡ºï¼‰:")
    while True:
        query = input("\n> ")
        if query.lower() == "exit":
            break
        
        answer, sources = rag_step_by_step(query)
        print(f"\nğŸ¤– æœ€ç»ˆç­”æ¡ˆ:\n{answer}\n")
        print("ğŸ“š å¼•ç”¨æ¥æº:")
        for i, doc in enumerate(sources, 1):
            print(f"  [{i}] {doc.page_content[:120]}...")